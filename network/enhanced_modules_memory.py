# network/enhanced_modules_memory.py - å®Œæ•´ç‰ˆæœ¬ï¼šä¸‰ä¸ªåˆ›æ–°ç‚¹çš„ç»Ÿä¸€å®ç°
# åŒ…å«ï¼šDSTMï¼ˆåŠ¨æ€è®°å¿†æ›´æ–°ï¼‰+ MQFFï¼ˆå¤šæŸ¥è¯¢ç‰¹å¾èåˆï¼‰+ ACGMï¼ˆè‡ªé€‚åº”é€šé“åˆ†ç»„ï¼‰

import torch
import torch.nn as nn
import torch.nn.functional as F
import math

class DynamicSpatioTemporalMemory(nn.Module):
    """
    åŠ¨æ€æ—¶ç©ºè®°å¿†æ¨¡å— (DSTM) - å®Œæ•´ç‰ˆæœ¬
    
    æ ¸å¿ƒåˆ›æ–°ï¼š
    1. å¯å­¦ä¹ çš„è§†è§‰è®°å¿†åº“ï¼Œå­˜å‚¨å…¸å‹çš„çœŸå®/ä¼ªé€ æ¨¡å¼
    2. æ™ºèƒ½æ£€ç´¢æœºåˆ¶ï¼ŒåŸºäºç›¸ä¼¼åº¦æ£€ç´¢ç›¸å…³è®°å¿†
    3. è‡ªé€‚åº”æ›´æ–°ç­–ç•¥ï¼Œæ ¹æ®æ–°ç»éªŒåŠ¨æ€è°ƒæ•´è®°å¿†å†…å®¹
    
    æŠ€æœ¯ç‰¹ç‚¹ï¼š
    - é€‰æ‹©æ€§å­˜å‚¨ï¼šåªè®°ä½æœ€å…·ä»£è¡¨æ€§çš„æ¨¡å¼
    - è”æƒ³æ£€ç´¢ï¼šé€šè¿‡ç›¸ä¼¼æ€§å¿«é€Ÿå®šä½ç›¸å…³è®°å¿†
    - é€‚åº”æ€§æ›´æ–°ï¼šæ ¹æ®æ–°ç»éªŒè°ƒæ•´è®°å¿†å†…å®¹
    """
    
    def __init__(self, input_channels, memory_size=256, memory_dim=512, 
                 update_rate=0.1, temperature=1.0, update_threshold=0.8):
        super(DynamicSpatioTemporalMemory, self).__init__()
        
        self.input_channels = input_channels
        self.memory_size = memory_size
        self.memory_dim = memory_dim
        self.update_rate = update_rate
        self.temperature = temperature
        self.update_threshold = update_threshold
        
        # æ ¸å¿ƒè®°å¿†åº“ - ä½¿ç”¨å¯è®­ç»ƒå‚æ•°ä½†ä¸å‚ä¸æ¢¯åº¦è®¡ç®—
        self.memory_bank = nn.Parameter(torch.randn(memory_size, memory_dim), requires_grad=False)
        self.memory_age = nn.Parameter(torch.zeros(memory_size), requires_grad=False)
        self.memory_quality = nn.Parameter(torch.ones(memory_size), requires_grad=False)
        self.memory_activation = nn.Parameter(torch.zeros(memory_size), requires_grad=False)
        
        # ç‰¹å¾ç¼–ç å™¨ - å°†è¾“å…¥ç‰¹å¾æ˜ å°„åˆ°è®°å¿†ç©ºé—´
        self.feature_encoder = nn.Sequential(
            nn.Conv2d(input_channels, memory_dim // 2, 1),
            nn.BatchNorm2d(memory_dim // 2),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(memory_dim // 2, memory_dim),
            nn.LayerNorm(memory_dim),
            nn.Dropout(0.1)
        )
        
        # è®°å¿†æ£€ç´¢ - å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶
        self.memory_attention = nn.MultiheadAttention(
            embed_dim=memory_dim,
            num_heads=8,
            batch_first=True,
            dropout=0.1
        )
        
        # è®°å¿†è´¨é‡è¯„ä¼°å™¨
        self.quality_evaluator = nn.Sequential(
            nn.Linear(memory_dim, memory_dim // 2),
            nn.ReLU(),
            nn.Linear(memory_dim // 2, 1),
            nn.Sigmoid()
        )
        
        # ç‰¹å¾é‡æ„å™¨ - å°†è®°å¿†ä¿¡æ¯è½¬æ¢ä¸ºç©ºé—´æƒé‡
        self.feature_reconstructor = nn.Sequential(
            nn.Linear(memory_dim, memory_dim // 2),
            nn.ReLU(),
            nn.Linear(memory_dim // 2, input_channels),
            nn.Sigmoid()
        )
        
        # ç©ºé—´æ³¨æ„åŠ› - ç”Ÿæˆç©ºé—´æƒé‡
        self.spatial_attention = nn.Sequential(
            nn.Conv2d(2, 1, 7, padding=3, bias=False),
            nn.Sigmoid()
        )
        
        # è®°å¿†èåˆé—¨æ§
        self.memory_gate = nn.Sequential(
            nn.Linear(memory_dim * 2, memory_dim),
            nn.Sigmoid()
        )
        
        self._initialize_memory()
        
    def _initialize_memory(self):
        """åˆå§‹åŒ–è®°å¿†åº“"""
        with torch.no_grad():
            # ä½¿ç”¨Xavieråˆå§‹åŒ–è®°å¿†åŸå‹
            nn.init.xavier_uniform_(self.memory_bank)
            
            # åˆå§‹åŒ–è®°å¿†è´¨é‡å’Œå¹´é¾„
            nn.init.ones_(self.memory_quality)
            nn.init.zeros_(self.memory_age)
            nn.init.zeros_(self.memory_activation)
    
    def forward(self, x):
        """
        å‰å‘ä¼ æ’­
        
        Args:
            x: è¾“å…¥ç‰¹å¾ (B, C, H, W)
            
        Returns:
            enhanced_features: è®°å¿†å¢å¼ºåçš„ç‰¹å¾ (B, C, H, W)
        """
        B, C, H, W = x.shape
        
        # 1. ç‰¹å¾ç¼–ç  - å°†è¾“å…¥ç‰¹å¾æ˜ å°„åˆ°è®°å¿†ç©ºé—´
        encoded_features = self.feature_encoder(x)  # (B, memory_dim)
        
        # 2. è®°å¿†æ£€ç´¢ - åŸºäºç›¸ä¼¼åº¦æ£€ç´¢ç›¸å…³è®°å¿†
        retrieved_memory, attention_weights = self._retrieve_memory(encoded_features)
        
        # 3. è®°å¿†èåˆ - èåˆå½“å‰ç‰¹å¾å’Œæ£€ç´¢è®°å¿†
        fused_features = self._fuse_memory(encoded_features, retrieved_memory)
        
        # 4. ç‰¹å¾é‡æ„ - ç”Ÿæˆç©ºé—´å¢å¼ºæƒé‡
        spatial_weights = self.feature_reconstructor(fused_features)
        spatial_weights = spatial_weights.unsqueeze(-1).unsqueeze(-1)  # (B, C, 1, 1)
        
        # 5. ç©ºé—´æ³¨æ„åŠ› - ç”Ÿæˆç©ºé—´æƒé‡
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        spatial_input = torch.cat([avg_out, max_out], dim=1)
        spatial_att = self.spatial_attention(spatial_input)
        
        # 6. ç‰¹å¾å¢å¼º - åº”ç”¨è®°å¿†æŒ‡å¯¼çš„å¢å¼º
        enhanced_features = x * spatial_weights * spatial_att
        
        # 7. è®°å¿†æ›´æ–° - è®­ç»ƒæ—¶æ›´æ–°è®°å¿†åº“
        if self.training:
            self._update_memory_safe(encoded_features.detach(), attention_weights.detach())
        
        return enhanced_features
    
    def _retrieve_memory(self, query_features):
        """
        æ™ºèƒ½è®°å¿†æ£€ç´¢æœºåˆ¶
        
        Args:
            query_features: æŸ¥è¯¢ç‰¹å¾ (B, memory_dim)
            
        Returns:
            retrieved_memory: æ£€ç´¢åˆ°çš„è®°å¿† (B, memory_dim)
            attention_weights: æ³¨æ„åŠ›æƒé‡ (B, memory_size)
        """
        B = query_features.size(0)
        
        # æ‰©å±•è®°å¿†åº“ç”¨äºæ‰¹æ¬¡è®¡ç®—
        memory_expanded = self.memory_bank.unsqueeze(0).expand(B, -1, -1)  # (B, memory_size, memory_dim)
        query_expanded = query_features.unsqueeze(1)  # (B, 1, memory_dim)
        
        # å¤šå¤´æ³¨æ„åŠ›æ£€ç´¢
        retrieved_memory, attention_weights = self.memory_attention(
            query_expanded, memory_expanded, memory_expanded
        )
        
        retrieved_memory = retrieved_memory.squeeze(1)  # (B, memory_dim)
        attention_weights = attention_weights.squeeze(1)  # (B, memory_size)
        
        return retrieved_memory, attention_weights
    
    def _fuse_memory(self, current_features, retrieved_memory):
        """
        è®°å¿†èåˆæœºåˆ¶
        
        Args:
            current_features: å½“å‰ç‰¹å¾ (B, memory_dim)
            retrieved_memory: æ£€ç´¢çš„è®°å¿† (B, memory_dim)
            
        Returns:
            fused_features: èåˆåçš„ç‰¹å¾ (B, memory_dim)
        """
        # æ‹¼æ¥å½“å‰ç‰¹å¾å’Œæ£€ç´¢è®°å¿†
        combined = torch.cat([current_features, retrieved_memory], dim=1)
        
        # é—¨æ§èåˆ
        gate = self.memory_gate(combined)
        fused_features = gate * current_features + (1 - gate) * retrieved_memory
        
        return fused_features
    
    def _update_memory_safe(self, new_features, attention_weights):
        """
        å®‰å…¨çš„è®°å¿†æ›´æ–°æœºåˆ¶
        
        æ›´æ–°ç­–ç•¥ï¼š
        1. å¦‚æœæ–°ç‰¹å¾ä¸ç°æœ‰è®°å¿†ç›¸ä¼¼åº¦é«˜ï¼Œæ›´æ–°è¯¥è®°å¿†
        2. å¦åˆ™ï¼Œæ›¿æ¢è´¨é‡æœ€ä½çš„è®°å¿†
        3. æ›´æ–°è®°å¿†è´¨é‡å’Œå¹´é¾„ä¿¡æ¯
        
        Args:
            new_features: æ–°çš„ç‰¹å¾ (B, memory_dim)
            attention_weights: æ³¨æ„åŠ›æƒé‡ (B, memory_size)
        """
        with torch.no_grad():
            if new_features.size(0) == 0:
                return
            
            # é€‰æ‹©æœ€é‡è¦çš„ç‰¹å¾è¿›è¡Œæ›´æ–°
            feature_importance = torch.norm(new_features, dim=1)
            if feature_importance.numel() == 0:
                return
                
            max_importance_idx = torch.argmax(feature_importance)
            selected_feature = new_features[max_importance_idx].clone()
            
            # è®¡ç®—ä¸ç°æœ‰è®°å¿†çš„ç›¸ä¼¼åº¦
            similarities = F.cosine_similarity(
                selected_feature.unsqueeze(0), 
                self.memory_bank.data,
                dim=1
            )
            
            max_similarity, max_sim_idx = torch.max(similarities, dim=0)
            
            # è¯„ä¼°æ–°ç‰¹å¾çš„è´¨é‡
            new_quality = self.quality_evaluator(selected_feature.unsqueeze(0)).item()
            
            # æ›´æ–°ç­–ç•¥
            if max_similarity > self.update_threshold:
                # æ›´æ–°ç°æœ‰è®°å¿†
                old_memory = self.memory_bank.data[max_sim_idx].clone()
                new_memory = (1 - self.update_rate) * old_memory + self.update_rate * selected_feature
                
                # å®‰å…¨æ›´æ–°
                self.memory_bank.data[max_sim_idx].copy_(new_memory)
                
                # æ›´æ–°è´¨é‡åˆ†æ•°
                old_quality = self.memory_quality.data[max_sim_idx].item()
                updated_quality = 0.9 * old_quality + 0.1 * new_quality
                self.memory_quality.data[max_sim_idx] = updated_quality
                
                # é‡ç½®å¹´é¾„
                self.memory_age.data[max_sim_idx] = 0
                
            else:
                # æ›¿æ¢è´¨é‡æœ€ä½çš„è®°å¿†
                quality_scores = self.memory_quality.data.clone()
                # è€ƒè™‘å¹´é¾„å› ç´ 
                age_penalty = self.memory_age.data / (self.memory_age.data.max() + 1e-8)
                adjusted_quality = quality_scores - 0.1 * age_penalty
                
                worst_idx = torch.argmin(adjusted_quality)
                
                # åªæœ‰å½“æ–°ç‰¹å¾è´¨é‡æ›´é«˜æ—¶æ‰æ›¿æ¢
                if new_quality > self.memory_quality.data[worst_idx]:
                    self.memory_bank.data[worst_idx].copy_(selected_feature)
                    self.memory_quality.data[worst_idx] = new_quality
                    self.memory_age.data[worst_idx] = 0
            
            # æ›´æ–°æ¿€æ´»è®¡æ•°
            self.memory_activation.data[max_sim_idx] += 1
            
            # å…¨å±€å¹´é¾„æ›´æ–°
            self.memory_age.data.add_(1)
            
            # é˜²æ­¢å¹´é¾„è¿‡å¤§
            max_age = self.memory_age.data.max()
            if max_age > 1000:
                self.memory_age.data.div_(2)


class MultiQueryFeatureFusion(nn.Module):
    """
    å¤šæŸ¥è¯¢ç‰¹å¾èåˆæ¨¡å— (MQFF)
    
    æ ¸å¿ƒåˆ›æ–°ï¼š
    1. ä¸“é—¨åŒ–æŸ¥è¯¢å‘é‡ï¼šé’ˆå¯¹ä¸åŒæ£€æµ‹ç»´åº¦è®¾è®¡ä¸“é—¨çš„æŸ¥è¯¢å‘é‡
    2. å±‚æ¬¡åŒ–äº¤å‰æ³¨æ„åŠ›ï¼šå¤šå±‚æ¬¡çš„æ³¨æ„åŠ›è®¡ç®—æœºåˆ¶
    3. æŸ¥è¯¢é—´åä½œï¼šä¸åŒæŸ¥è¯¢ä¹‹é—´çš„ä¿¡æ¯äº¤æ¢å’Œåä½œ
    
    æŸ¥è¯¢å‘é‡ä¸“é—¨åŒ–ï¼š
    - Q0, Q4: è¾¹ç¼˜/è½®å»“æ£€æµ‹ï¼ˆé«˜é€šæ»¤æ³¢åˆå§‹åŒ–ï¼‰
    - Q1, Q5: çº¹ç†ä¸€è‡´æ€§æ£€æµ‹ï¼ˆGaboræ»¤æ³¢åˆå§‹åŒ–ï¼‰
    - Q2, Q6: å…‰ç…§/é¢œè‰²æ£€æµ‹ï¼ˆè‰²å½©ç©ºé—´åˆå§‹åŒ–ï¼‰
    - Q3, Q7: å…¨å±€è¯­ä¹‰æ£€æµ‹ï¼ˆè¯­ä¹‰åˆ†å‰²åˆå§‹åŒ–ï¼‰
    """
    
    def __init__(self, input_channels, num_queries=8, query_dim=256, num_heads=8, dropout=0.1):
        super(MultiQueryFeatureFusion, self).__init__()
        
        self.input_channels = input_channels
        self.num_queries = num_queries
        self.query_dim = query_dim
        self.num_heads = num_heads
        self.head_dim = query_dim // num_heads
        self.scale = self.head_dim ** -0.5
        
        assert query_dim % num_heads == 0, "query_dim must be divisible by num_heads"
        
        # å¯å­¦ä¹ çš„ä¸“é—¨åŒ–æŸ¥è¯¢å‘é‡
        self.query_vectors = nn.Parameter(torch.randn(num_queries, query_dim))
        
        # æŸ¥è¯¢ä¸“é—¨åŒ–å™¨
        self.query_specializers = nn.ModuleList([
            self._create_query_specializer(i) for i in range(num_queries)
        ])
        
        # è¾“å…¥ç‰¹å¾æŠ•å½±
        self.input_projection = nn.Conv2d(input_channels, query_dim, 1)
        
        # å¤šå¤´äº¤å‰æ³¨æ„åŠ›
        self.cross_attention = nn.MultiheadAttention(
            embed_dim=query_dim,
            num_heads=num_heads,
            dropout=dropout,
            batch_first=True
        )
        
        # æŸ¥è¯¢é—´åä½œæœºåˆ¶
        self.query_collaboration = QueryCollaboration(num_queries, query_dim)
        
        # å±‚æ¬¡åŒ–ç‰¹å¾èåˆ
        self.hierarchical_fusion = HierarchicalFeatureFusion(query_dim, input_channels, num_queries)
        
        # ä½ç½®ç¼–ç 
        self.position_encoding = PositionalEncoding2D(query_dim)
        
        # è¾“å‡ºæŠ•å½±
        self.output_projection = nn.Sequential(
            nn.Conv2d(input_channels, input_channels, 3, padding=1),
            nn.BatchNorm2d(input_channels),
            nn.ReLU()
        )
        
        self._initialize_parameters()
    
    def _create_query_specializer(self, query_idx):
        """åˆ›å»ºä¸“é—¨åŒ–çš„æŸ¥è¯¢å¤„ç†å™¨"""
        if query_idx in [0, 4]:  # è¾¹ç¼˜/è½®å»“æ£€æµ‹
            return nn.Sequential(
                nn.Linear(self.query_dim, self.query_dim),
                nn.ReLU(),
                nn.Linear(self.query_dim, self.query_dim),
                nn.Tanh()
            )
        elif query_idx in [1, 5]:  # çº¹ç†ä¸€è‡´æ€§æ£€æµ‹
            return nn.Sequential(
                nn.Linear(self.query_dim, self.query_dim * 2),
                nn.GELU(),
                nn.Linear(self.query_dim * 2, self.query_dim),
                nn.Sigmoid()
            )
        elif query_idx in [2, 6]:  # å…‰ç…§/é¢œè‰²æ£€æµ‹
            return nn.Sequential(
                nn.Linear(self.query_dim, self.query_dim),
                nn.LeakyReLU(0.2),
                nn.Linear(self.query_dim, self.query_dim),
                nn.Hardtanh()
            )
        else:  # å…¨å±€è¯­ä¹‰æ£€æµ‹
            return nn.Sequential(
                nn.Linear(self.query_dim, self.query_dim),
                nn.ReLU(),
                nn.Dropout(0.1),
                nn.Linear(self.query_dim, self.query_dim)
            )
    
    def _initialize_parameters(self):
        """ä¸“é—¨åŒ–åˆå§‹åŒ–æŸ¥è¯¢å‘é‡"""
        with torch.no_grad():
            for i in range(self.num_queries):
                if i % 4 == 0:  # è¾¹ç¼˜æ£€æµ‹
                    nn.init.xavier_uniform_(self.query_vectors.data[i:i+1])
                elif i % 4 == 1:  # çº¹ç†æ£€æµ‹
                    nn.init.kaiming_uniform_(self.query_vectors.data[i:i+1])
                elif i % 4 == 2:  # é¢œè‰²æ£€æµ‹
                    nn.init.normal_(self.query_vectors.data[i:i+1], 0, 0.02)
                else:  # è¯­ä¹‰æ£€æµ‹
                    nn.init.orthogonal_(self.query_vectors.data[i:i+1])
    
    def forward(self, x):
        """
        å‰å‘ä¼ æ’­
        
        Args:
            x: è¾“å…¥ç‰¹å¾ (B, C, H, W)
            
        Returns:
            enhanced_features: å¤šæŸ¥è¯¢å¢å¼ºåçš„ç‰¹å¾ (B, C, H, W)
        """
        B, C, H, W = x.shape
        
        # 1. è¾“å…¥ç‰¹å¾æŠ•å½±
        projected_features = self.input_projection(x)  # (B, query_dim, H, W)
        
        # 2. æ·»åŠ ä½ç½®ç¼–ç 
        projected_features = self.position_encoding(projected_features)
        
        # 3. ç‰¹å¾å±•å¹³ç”¨äºæ³¨æ„åŠ›è®¡ç®—
        feature_tokens = projected_features.flatten(2).transpose(1, 2)  # (B, H*W, query_dim)
        
        # 4. æŸ¥è¯¢ä¸“é—¨åŒ–
        specialized_queries = []
        for i, specializer in enumerate(self.query_specializers):
            specialized_query = specializer(self.query_vectors[i].unsqueeze(0))
            specialized_queries.append(specialized_query)
        
        queries = torch.cat(specialized_queries, dim=0).unsqueeze(0).expand(B, -1, -1)
        
        # 5. å¤šå¤´äº¤å‰æ³¨æ„åŠ›
        query_responses, attention_weights = self.cross_attention(
            queries, feature_tokens, feature_tokens
        )
        
        # 6. æŸ¥è¯¢é—´åä½œ
        collaborated_queries = self.query_collaboration(query_responses)
        
        # 7. å±‚æ¬¡åŒ–ç‰¹å¾èåˆ
        enhanced_features = self.hierarchical_fusion(
            collaborated_queries, projected_features, attention_weights
        )
        
        # 8. è¾“å‡ºæŠ•å½±
        output = self.output_projection(enhanced_features)
        
        return output


class QueryCollaboration(nn.Module):
    """æŸ¥è¯¢é—´åä½œæœºåˆ¶"""
    
    def __init__(self, num_queries, query_dim):
        super(QueryCollaboration, self).__init__()
        
        # æŸ¥è¯¢é—´é€šä¿¡çŸ©é˜µ
        self.communication_matrix = nn.Parameter(
            torch.eye(num_queries) + 0.1 * torch.randn(num_queries, num_queries)
        )
        
        # åä½œé—¨æ§
        self.collaboration_gate = nn.Sequential(
            nn.Linear(query_dim * 2, query_dim),
            nn.Sigmoid()
        )
        
        # ä¿¡æ¯èåˆ
        self.information_fusion = nn.Sequential(
            nn.Linear(query_dim, query_dim),
            nn.LayerNorm(query_dim),
            nn.ReLU(),
            nn.Linear(query_dim, query_dim)
        )
    
    def forward(self, query_responses):
        """
        Args:
            query_responses: (B, num_queries, query_dim)
        Returns:
            collaborated_queries: (B, num_queries, query_dim)
        """
        B, num_queries, query_dim = query_responses.shape
        
        # æŸ¥è¯¢é—´ä¿¡æ¯äº¤æ¢
        communication_weights = F.softmax(self.communication_matrix, dim=1)
        communicated = torch.matmul(communication_weights, query_responses)
        
        # é—¨æ§èåˆ
        combined = torch.cat([query_responses, communicated], dim=-1)
        gates = self.collaboration_gate(combined)
        
        # è‡ªé€‚åº”èåˆ
        collaborated = gates * query_responses + (1 - gates) * communicated
        
        # ä¿¡æ¯èåˆ
        output = self.information_fusion(collaborated) + query_responses
        
        return output


class HierarchicalFeatureFusion(nn.Module):
    """å±‚æ¬¡åŒ–ç‰¹å¾èåˆ"""
    
    def __init__(self, query_dim, output_channels, num_queries):
        super(HierarchicalFeatureFusion, self).__init__()
        
        self.query_dim = query_dim
        self.output_channels = output_channels
        self.num_queries = num_queries
        
        # æŸ¥è¯¢èšåˆ
        self.query_aggregator = nn.Sequential(
            nn.Linear(query_dim * num_queries, output_channels),
            nn.Sigmoid()
        )
        
        # ç‰¹å¾è½¬æ¢
        self.feature_transform = nn.Sequential(
            nn.Conv2d(query_dim, output_channels, 1),
            nn.BatchNorm2d(output_channels),
            nn.ReLU()
        )
        
        # ç©ºé—´æ³¨æ„åŠ›
        self.spatial_attention = nn.Sequential(
            nn.Conv2d(output_channels, 1, 1),
            nn.Sigmoid()
        )
        
        # å¤šå°ºåº¦èåˆ
        self.multi_scale_fusion = nn.ModuleList([
            nn.AdaptiveAvgPool2d(1),
            nn.AdaptiveAvgPool2d(2),
            nn.AdaptiveAvgPool2d(4)
        ])
        
        self.scale_fusion = nn.Sequential(
            nn.Linear(output_channels * 21, output_channels),  # 1+4+16=21
            nn.ReLU(),
            nn.Linear(output_channels, output_channels),
            nn.Sigmoid()
        )
    
    def forward(self, query_responses, projected_features, attention_weights):
        """
        Args:
            query_responses: (B, num_queries, query_dim)
            projected_features: (B, query_dim, H, W)
            attention_weights: attention weights
        Returns:
            enhanced_features: (B, output_channels, H, W)
        """
        B, num_queries, query_dim = query_responses.shape
        _, _, H, W = projected_features.shape
        
        # 1. æŸ¥è¯¢èšåˆä¸ºé€šé“æƒé‡
        flattened_queries = query_responses.contiguous().view(B, -1)
        channel_weights = self.query_aggregator(flattened_queries)
        channel_weights = channel_weights.unsqueeze(-1).unsqueeze(-1)
        
        # 2. ç‰¹å¾è½¬æ¢
        transformed_features = self.feature_transform(projected_features)
        
        # 3. ç©ºé—´æ³¨æ„åŠ›
        spatial_att = self.spatial_attention(transformed_features)
        
        # 4. å¤šå°ºåº¦ç‰¹å¾èåˆ
        multi_scale_features = []
        for pool in self.multi_scale_fusion:
            pooled = pool(transformed_features)
            multi_scale_features.append(pooled.flatten(1))
        
        combined_scales = torch.cat(multi_scale_features, dim=1)
        scale_weights = self.scale_fusion(combined_scales)
        scale_weights = scale_weights.unsqueeze(-1).unsqueeze(-1)
        
        # 5. æœ€ç»ˆç‰¹å¾èåˆ
        enhanced_features = transformed_features * channel_weights * spatial_att * scale_weights
        
        return enhanced_features


class AdaptiveChannelGroupingMechanism(nn.Module):
    """
    è‡ªé€‚åº”é€šé“åˆ†ç»„æœºåˆ¶ (ACGM)
    
    æ ¸å¿ƒåˆ›æ–°ï¼š
    1. å†…å®¹æ„ŸçŸ¥åˆ†ç»„ï¼šæ ¹æ®è¾“å…¥å†…å®¹åŠ¨æ€è°ƒæ•´é€šé“åˆ†ç»„ç­–ç•¥
    2. åŠ¨æ€è·¯ç”±ä¼˜åŒ–ï¼šé€šè¿‡è¿­ä»£è·¯ç”±ä¼˜åŒ–ä¿¡æ¯æµåŠ¨
    3. ç»„å†…å¤–äº¤äº’ï¼šç»„å†…å¢å¼ºå’Œç»„é—´åä½œçš„ç»Ÿä¸€æœºåˆ¶
    
    æŠ€æœ¯ç‰¹ç‚¹ï¼š
    - æ‰“ç ´å›ºå®šé€šé“åˆ†ç»„çš„é™åˆ¶
    - æ ¹æ®è¾“å…¥å†…å®¹è‡ªé€‚åº”è°ƒæ•´åˆ†ç»„
    - ä¼˜åŒ–ç‰¹å¾è¡¨ç¤ºæ•ˆç‡
    """
    
    def __init__(self, input_channels, num_groups=8, reduction_ratio=16, 
                 routing_iterations=3, temperature=1.0):
        super(AdaptiveChannelGroupingMechanism, self).__init__()
        
        self.input_channels = input_channels
        # ç¡®ä¿ç»„æ•°èƒ½æ•´é™¤é€šé“æ•°
        while input_channels % num_groups != 0 and num_groups > 1:
            num_groups -= 1
        self.num_groups = num_groups
        self.group_size = input_channels // num_groups
        self.routing_iterations = routing_iterations
        self.temperature = temperature
        
        print(f"ACGM: {input_channels} channels, {num_groups} groups, {self.group_size} channels per group")
        
        # å†…å®¹æ„ŸçŸ¥åˆ†ç»„ç­–ç•¥å­¦ä¹ å™¨
        self.content_analyzer = ContentAwareGrouping(input_channels, num_groups, reduction_ratio)
        
        # åŠ¨æ€è·¯ç”±å™¨
        self.dynamic_router = DynamicChannelRouter(input_channels, num_groups, routing_iterations)
        
        # ç»„å†…ç‰¹å¾å¢å¼ºå™¨
        self.intra_group_enhancers = nn.ModuleList([
            IntraGroupEnhancer(self.group_size) for _ in range(num_groups)
        ])
        
        # ç»„é—´äº¤äº’æ¨¡å—
        self.inter_group_interaction = InterGroupInteraction(num_groups, self.group_size)
        
        # è‡ªé€‚åº”èåˆé—¨æ§
        self.adaptive_fusion = AdaptiveFusionGate(input_channels, num_groups)
        
        # å…¨å±€ç‰¹å¾æ•´åˆ
        self.global_integration = nn.Sequential(
            nn.Conv2d(input_channels, input_channels, 3, padding=1),
            nn.BatchNorm2d(input_channels),
            nn.ReLU(),
            nn.Conv2d(input_channels, input_channels, 1),
            nn.BatchNorm2d(input_channels)
        )
    
    def forward(self, x):
        """
        å‰å‘ä¼ æ’­
        
        Args:
            x: è¾“å…¥ç‰¹å¾ (B, C, H, W)
            
        Returns:
            enhanced_features: è‡ªé€‚åº”åˆ†ç»„å¢å¼ºåçš„ç‰¹å¾ (B, C, H, W)
        """
        B, C, H, W = x.shape
        
        # 1. å†…å®¹æ„ŸçŸ¥åˆ†ç»„ç­–ç•¥å­¦ä¹ 
        group_assignments, group_confidence = self.content_analyzer(x)
        
        # 2. åŠ¨æ€è·¯ç”±ä¼˜åŒ–
        routing_weights, routed_features = self.dynamic_router(x, group_assignments)
        
        # 3. ç»„å†…ç‰¹å¾å¢å¼º
        enhanced_groups = []
        for i, enhancer in enumerate(self.intra_group_enhancers):
            start_idx = i * self.group_size
            end_idx = start_idx + self.group_size
            
            group_features = routed_features[:, start_idx:end_idx]
            enhanced_group = enhancer(group_features)
            enhanced_groups.append(enhanced_group)
        
        # 4. ç»„é—´äº¤äº’
        interacted_groups = self.inter_group_interaction(enhanced_groups)
        
        # 5. ç‰¹å¾é‡ç»„
        reorganized_features = torch.cat(interacted_groups, dim=1)
        
        # 6. è‡ªé€‚åº”èåˆ
        fused_features = self.adaptive_fusion(x, reorganized_features, group_confidence)
        
        # 7. å…¨å±€ç‰¹å¾æ•´åˆ
        integrated_features = self.global_integration(fused_features)
        
        # 8. æ®‹å·®è¿æ¥
        output = integrated_features + x
        
        return output


class ContentAwareGrouping(nn.Module):
    """å†…å®¹æ„ŸçŸ¥åˆ†ç»„ç­–ç•¥å­¦ä¹ å™¨"""
    
    def __init__(self, input_channels, num_groups, reduction_ratio):
        super(ContentAwareGrouping, self).__init__()
        
        self.input_channels = input_channels
        self.num_groups = num_groups
        
        # å†…å®¹åˆ†æç½‘ç»œ
        self.content_analyzer = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(input_channels, input_channels // reduction_ratio, 1),
            nn.ReLU(),
            nn.Conv2d(input_channels // reduction_ratio, input_channels // reduction_ratio, 1),
            nn.ReLU(),
            nn.Conv2d(input_channels // reduction_ratio, input_channels * num_groups, 1)
        )
        
        # åˆ†ç»„ç­–ç•¥ç”Ÿæˆå™¨
        self.strategy_generator = nn.Sequential(
            nn.Linear(input_channels * num_groups, input_channels),
            nn.ReLU(),
            nn.Linear(input_channels, input_channels * num_groups),
            nn.Softmax(dim=-1)
        )
        
        # ç½®ä¿¡åº¦è¯„ä¼°å™¨
        self.confidence_evaluator = nn.Sequential(
            nn.Linear(input_channels * num_groups, input_channels // 4),
            nn.ReLU(),
            nn.Linear(input_channels // 4, 1),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        """
        Args:
            x: è¾“å…¥ç‰¹å¾ (B, C, H, W)
        Returns:
            group_assignments: åˆ†ç»„åˆ†é… (B, C, num_groups)
            group_confidence: åˆ†ç»„ç½®ä¿¡åº¦ (B, 1)
        """
        B, C, H, W = x.shape
        
        # åˆ†æè¾“å…¥å†…å®¹
        content_features = self.content_analyzer(x)  # (B, C*num_groups, 1, 1)
        content_features = content_features.flatten(1)  # (B, C*num_groups)
        
        # ç”Ÿæˆåˆ†ç»„ç­–ç•¥
        group_assignments = self.strategy_generator(content_features)
        group_assignments = group_assignments.view(B, C, self.num_groups)
        
        # è¯„ä¼°ç½®ä¿¡åº¦
        group_confidence = self.confidence_evaluator(content_features)
        
        return group_assignments, group_confidence


class DynamicChannelRouter(nn.Module):
    """åŠ¨æ€é€šé“è·¯ç”±å™¨"""
    
    def __init__(self, input_channels, num_groups, routing_iterations):
        super(DynamicChannelRouter, self).__init__()
        
        self.input_channels = input_channels
        self.num_groups = num_groups
        self.routing_iterations = routing_iterations
        
        # è·¯ç”±é¢„æµ‹ç½‘ç»œ
        self.routing_predictor = nn.Sequential(
            nn.Conv2d(input_channels, input_channels // 4, 1),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(input_channels // 4, input_channels * num_groups)
        )
        
        # è·¯ç”±æƒé‡åˆå§‹åŒ–
        self.register_buffer('routing_bias', torch.zeros(num_groups, input_channels))
    
    def forward(self, x, group_assignments):
        """
        Args:
            x: è¾“å…¥ç‰¹å¾ (B, C, H, W)
            group_assignments: åˆ†ç»„åˆ†é… (B, C, num_groups)
        Returns:
            routing_weights: æœ€ç»ˆè·¯ç”±æƒé‡ (B, C, num_groups)
            routed_features: è·¯ç”±åçš„ç‰¹å¾ (B, C, H, W)
        """
        B, C, H, W = x.shape
        
        # åˆå§‹è·¯ç”±logits
        routing_logits = self.routing_predictor(x)
        routing_logits = routing_logits.view(B, C, self.num_groups)
        
        # ç»“åˆåˆ†ç»„åˆ†é…
        routing_logits = routing_logits + torch.log(group_assignments + 1e-8)
        
        # åŠ¨æ€è·¯ç”±è¿­ä»£
        for iteration in range(self.routing_iterations):
            # è®¡ç®—è·¯ç”±æƒé‡
            routing_weights = F.softmax(routing_logits, dim=-1)
            
            # è®¡ç®—ç»„è¾“å‡º
            group_outputs = []
            for g in range(self.num_groups):
                weights = routing_weights[:, :, g].unsqueeze(-1).unsqueeze(-1)
                group_output = (x * weights).sum(dim=1, keepdim=True)
                group_outputs.append(group_output)
            
            # æ›´æ–°è·¯ç”±logitsï¼ˆåŸºäºä¸€è‡´æ€§ï¼‰
            if iteration < self.routing_iterations - 1:
                agreements = self._compute_agreement(x, group_outputs)
                routing_logits = routing_logits + agreements
        
        # åº”ç”¨æœ€ç»ˆè·¯ç”±
        final_weights = F.softmax(routing_logits, dim=-1)
        routed_features = x  # ä¿æŒåŸå§‹ç‰¹å¾ç»“æ„
        
        return final_weights, routed_features
    
    def _compute_agreement(self, inputs, group_outputs):
        """è®¡ç®—è¾“å…¥ä¸ç»„è¾“å‡ºçš„ä¸€è‡´æ€§"""
        agreements = []
        B, C, H, W = inputs.shape
        
        for g, group_output in enumerate(group_outputs):
            # æ‰©å±•ç»„è¾“å‡ºåˆ°è¾“å…¥ç»´åº¦
            expanded_output = group_output.expand(-1, C, -1, -1)
            
            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            inputs_flat = inputs.flatten(2)  # (B, C, H*W)
            output_flat = expanded_output.flatten(2)  # (B, C, H*W)
            
            similarity = F.cosine_similarity(inputs_flat, output_flat, dim=2)  # (B, C)
            agreements.append(similarity)
        
        return torch.stack(agreements, dim=-1)  # (B, C, num_groups)


class IntraGroupEnhancer(nn.Module):
    """ç»„å†…ç‰¹å¾å¢å¼ºå™¨"""
    
    def __init__(self, group_size):
        super(IntraGroupEnhancer, self).__init__()
        
        self.group_size = group_size
        
        # é€šé“é—´äº¤äº’
        self.channel_interaction = nn.Sequential(
            nn.Conv2d(group_size, group_size, 1, groups=group_size),
            nn.BatchNorm2d(group_size),
            nn.ReLU(),
            nn.Conv2d(group_size, group_size, 3, padding=1, groups=group_size),
            nn.BatchNorm2d(group_size),
            nn.ReLU()
        )
        
        # é€šé“é‡è¦æ€§å­¦ä¹ 
        self.channel_importance = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(group_size, max(group_size // 4, 1), 1),
            nn.ReLU(),
            nn.Conv2d(max(group_size // 4, 1), group_size, 1),
            nn.Sigmoid()
        )
        
        # ç©ºé—´å¢å¼º
        self.spatial_enhancement = nn.Sequential(
            nn.Conv2d(group_size, group_size, 3, padding=1),
            nn.BatchNorm2d(group_size),
            nn.ReLU(),
            nn.Conv2d(group_size, group_size, 1),
            nn.BatchNorm2d(group_size)
        )
    
    def forward(self, group_features):
        """
        Args:
            group_features: (B, group_size, H, W)
        Returns:
            enhanced_features: (B, group_size, H, W)
        """
        # é€šé“äº¤äº’
        interacted = self.channel_interaction(group_features)
        
        # é‡è¦æ€§åŠ æƒ
        importance = self.channel_importance(group_features)
        weighted = interacted * importance
        
        # ç©ºé—´å¢å¼º
        enhanced = self.spatial_enhancement(weighted)
        
        # æ®‹å·®è¿æ¥
        output = enhanced + group_features
        
        return output


class InterGroupInteraction(nn.Module):
    """ç»„é—´äº¤äº’æ¨¡å—"""
    
    def __init__(self, num_groups, group_size):
        super(InterGroupInteraction, self).__init__()
        
        self.num_groups = num_groups
        self.group_size = group_size
        
        # ç»„é—´æ³¨æ„åŠ›
        self.inter_group_attention = nn.MultiheadAttention(
            embed_dim=group_size,
            num_heads=max(group_size // 32, 1),
            batch_first=True,
            dropout=0.1
        )
        
        # ç»„èåˆç½‘ç»œ
        self.group_fusion = nn.Sequential(
            nn.Linear(group_size * num_groups, group_size * num_groups // 2),
            nn.ReLU(),
            nn.Linear(group_size * num_groups // 2, group_size * num_groups),
            nn.Sigmoid()
        )
        
        # ç»„çº§å½’ä¸€åŒ–
        self.group_norm = nn.GroupNorm(num_groups, group_size * num_groups)
    
    def forward(self, group_list):
        """
        Args:
            group_list: List of (B, group_size, H, W)
        Returns:
            interacted_groups: List of (B, group_size, H, W)
        """
        B, _, H, W = group_list[0].shape
        
        # å°†ç»„ç‰¹å¾å±•å¹³ç”¨äºæ³¨æ„åŠ›è®¡ç®—
        group_tokens = []
        for group in group_list:
            token = F.adaptive_avg_pool2d(group, 1).flatten(1)  # (B, group_size)
            group_tokens.append(token)
        
        group_tokens = torch.stack(group_tokens, dim=1)  # (B, num_groups, group_size)
        
        # ç»„é—´æ³¨æ„åŠ›
        attended_tokens, _ = self.inter_group_attention(
            group_tokens, group_tokens, group_tokens
        )
        
        # å…¨å±€èåˆæƒé‡
        flattened_tokens = attended_tokens.flatten(1)  # (B, num_groups * group_size)
        fusion_weights = self.group_fusion(flattened_tokens)
        fusion_weights = fusion_weights.view(B, self.num_groups, self.group_size)
        
        # åº”ç”¨èåˆæƒé‡åˆ°åŸå§‹ç»„ç‰¹å¾
        interacted_groups = []
        for i, group in enumerate(group_list):
            weight = fusion_weights[:, i].unsqueeze(-1).unsqueeze(-1)
            enhanced_group = group * weight
            interacted_groups.append(enhanced_group)
        
        return interacted_groups


class AdaptiveFusionGate(nn.Module):
    """è‡ªé€‚åº”èåˆé—¨æ§"""
    
    def __init__(self, channels, num_groups):
        super(AdaptiveFusionGate, self).__init__()
        
        self.channels = channels
        self.num_groups = num_groups
        
        # èåˆé—¨æ§ç½‘ç»œ
        self.fusion_gate = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(channels * 2, channels // 4, 1),
            nn.ReLU(),
            nn.Conv2d(channels // 4, 1, 1),
            nn.Sigmoid()
        )
        
        # é€šé“çº§é—¨æ§
        self.channel_gate = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(channels * 2, channels // 2, 1),
            nn.ReLU(),
            nn.Conv2d(channels // 2, channels, 1),
            nn.Sigmoid()
        )
        
        # ç½®ä¿¡åº¦è°ƒåˆ¶
        self.confidence_modulator = nn.Sequential(
            nn.Linear(1, channels // 4),
            nn.ReLU(),
            nn.Linear(channels // 4, 1),
            nn.Sigmoid()
        )
    
    def forward(self, original_features, enhanced_features, group_confidence):
        """
        Args:
            original_features: (B, C, H, W)
            enhanced_features: (B, C, H, W)
            group_confidence: (B, 1)
        Returns:
            fused_features: (B, C, H, W)
        """
        # ç‰¹å¾æ‹¼æ¥
        combined = torch.cat([original_features, enhanced_features], dim=1)
        
        # ç©ºé—´é—¨æ§
        spatial_gate = self.fusion_gate(combined)
        
        # é€šé“é—¨æ§
        channel_gate = self.channel_gate(combined)
        
        # ç½®ä¿¡åº¦è°ƒåˆ¶
        confidence_weight = self.confidence_modulator(group_confidence)
        confidence_weight = confidence_weight.unsqueeze(-1).unsqueeze(-1)
        
        # è‡ªé€‚åº”èåˆ
        fused_features = (
            confidence_weight * spatial_gate * channel_gate * enhanced_features +
            (1 - confidence_weight * spatial_gate) * original_features
        )
        
        return fused_features


class PositionalEncoding2D(nn.Module):
    """2Dä½ç½®ç¼–ç """
    
    def __init__(self, channels, temperature=10000):
        super(PositionalEncoding2D, self).__init__()
        self.channels = channels
        self.temperature = temperature
        
    def forward(self, x):
        """
        Args:
            x: (B, C, H, W)
        Returns:
            encoded: (B, C, H, W)
        """
        B, C, H, W = x.shape
        device = x.device
        
        # ç”Ÿæˆä½ç½®ç½‘æ ¼
        y_pos = torch.arange(H, dtype=torch.float32, device=device).unsqueeze(1).repeat(1, W)
        x_pos = torch.arange(W, dtype=torch.float32, device=device).unsqueeze(0).repeat(H, 1)
        
        # å½’ä¸€åŒ–ä½ç½®
        if H > 1:
            y_pos = y_pos / (H - 1)
        if W > 1:
            x_pos = x_pos / (W - 1)
        
        # è®¡ç®—ä½ç½®ç¼–ç 
        encoding_dim = min(C // 4, 64)  # é™åˆ¶ç¼–ç ç»´åº¦
        dim_t = torch.arange(encoding_dim, dtype=torch.float32, device=device)
        dim_t = self.temperature ** (2 * (dim_t // 2) / encoding_dim)
        
        pos_x = x_pos.unsqueeze(-1) / dim_t
        pos_y = y_pos.unsqueeze(-1) / dim_t
        
        pos_x = torch.stack((pos_x[:, :, 0::2].sin(), pos_x[:, :, 1::2].cos()), dim=3).flatten(2)
        pos_y = torch.stack((pos_y[:, :, 0::2].sin(), pos_y[:, :, 1::2].cos()), dim=3).flatten(2)
        
        pos_encoding = torch.cat((pos_y, pos_x), dim=2).permute(2, 0, 1).unsqueeze(0)
        
        # è°ƒæ•´ç¼–ç ç»´åº¦ä»¥åŒ¹é…è¾“å…¥
        if pos_encoding.size(1) < C:
            padding = torch.zeros(1, C - pos_encoding.size(1), H, W, device=device)
            pos_encoding = torch.cat([pos_encoding, padding], dim=1)
        elif pos_encoding.size(1) > C:
            pos_encoding = pos_encoding[:, :C]
        
        return x + pos_encoding.expand(B, -1, -1, -1)


# ç®€åŒ–ç‰ˆæœ¬çš„ACGMï¼ˆå¦‚æœä¸Šé¢çš„ç‰ˆæœ¬è¿‡äºå¤æ‚ï¼‰
class SimplifiedAdaptiveChannelGroupingMechanism(nn.Module):
    """ç®€åŒ–çš„è‡ªé€‚åº”é€šé“åˆ†ç»„æœºåˆ¶"""
    
    def __init__(self, input_channels, num_groups=8, reduction_ratio=16):
        super(SimplifiedAdaptiveChannelGroupingMechanism, self).__init__()
        
        self.input_channels = input_channels
        # ç¡®ä¿ç»„æ•°èƒ½æ•´é™¤é€šé“æ•°
        while input_channels % num_groups != 0 and num_groups > 1:
            num_groups -= 1
        self.num_groups = num_groups
        self.group_size = input_channels // num_groups
        
        print(f"SimplifiedACGM: {input_channels} channels, {num_groups} groups, {self.group_size} channels per group")
        
        # é€šé“æ³¨æ„åŠ›
        self.channel_attention = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(input_channels, max(input_channels // reduction_ratio, 1), 1),
            nn.ReLU(),
            nn.Conv2d(max(input_channels // reduction_ratio, 1), input_channels, 1),
            nn.Sigmoid()
        )
        
        # ç©ºé—´æ³¨æ„åŠ›
        self.spatial_attention = nn.Sequential(
            nn.Conv2d(2, 1, 7, padding=3, bias=False),
            nn.Sigmoid()
        )
        
        # ç»„çº§ç‰¹å¾å¢å¼º
        self.group_enhancers = nn.ModuleList([
            nn.Sequential(
                nn.Conv2d(self.group_size, self.group_size, 3, padding=1, groups=self.group_size),
                nn.BatchNorm2d(self.group_size),
                nn.ReLU(),
                nn.Conv2d(self.group_size, self.group_size, 1),
                nn.BatchNorm2d(self.group_size)
            ) for _ in range(num_groups)
        ])
        
        # ç»„é—´ä¿¡æ¯äº¤æ¢
        self.inter_group_conv = nn.Conv2d(input_channels, input_channels, 1)
        
    def forward(self, x):
        """
        Args:
            x: (B, C, H, W)
        Returns:
            enhanced_features: (B, C, H, W)
        """
        B, C, H, W = x.shape
        
        # é€šé“æ³¨æ„åŠ›
        channel_att = self.channel_attention(x)
        
        # ç©ºé—´æ³¨æ„åŠ›
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        spatial_input = torch.cat([avg_out, max_out], dim=1)
        spatial_att = self.spatial_attention(spatial_input)
        
        # åˆ†ç»„å¤„ç†
        enhanced_groups = []
        for i, enhancer in enumerate(self.group_enhancers):
            start_idx = i * self.group_size
            end_idx = start_idx + self.group_size
            
            group_features = x[:, start_idx:end_idx]
            enhanced_group = enhancer(group_features) + group_features
            enhanced_groups.append(enhanced_group)
        
        # ç»„åˆç‰¹å¾
        enhanced_x = torch.cat(enhanced_groups, dim=1)
        
        # ç»„é—´ä¿¡æ¯äº¤æ¢
        exchanged_x = self.inter_group_conv(enhanced_x)
        
        # åº”ç”¨æ³¨æ„åŠ›
        final_features = exchanged_x * channel_att * spatial_att
        
        # æ®‹å·®è¿æ¥
        output = final_features + x
        
        return output


# æµ‹è¯•å‡½æ•°
def test_enhanced_modules():
    """æµ‹è¯•å¢å¼ºæ¨¡å—çš„åŠŸèƒ½"""
    print("ğŸ§ª Testing Enhanced Modules with Dynamic Memory Update...")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # æµ‹è¯•å‚æ•°
    batch_size = 2
    input_channels = 1792
    H, W = 7, 7
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    x = torch.randn(batch_size, input_channels, H, W).to(device)
    
    # æµ‹è¯• DSTMï¼ˆå¸¦åŠ¨æ€è®°å¿†æ›´æ–°ï¼‰
    print("\nğŸ”¬ Testing DSTM with Dynamic Memory Update...")
    try:
        dstm = DynamicSpatioTemporalMemory(
            input_channels=input_channels,
            memory_size=128,
            memory_dim=256,
            update_rate=0.1
        ).to(device)
        
        # è®­ç»ƒæ¨¡å¼æµ‹è¯•
        dstm.train()
        out_dstm = dstm(x)
        print(f"âœ… DSTM Training Mode - Input: {x.shape}, Output: {out_dstm.shape}")
        
        # æµ‹è¯•è®°å¿†æ›´æ–°
        loss = out_dstm.mean()
        loss.backward()
        print("âœ… DSTM backward pass and memory update successful!")
        
        # è¯„ä¼°æ¨¡å¼æµ‹è¯•
        dstm.eval()
        with torch.no_grad():
            out_eval = dstm(x)
        print(f"âœ… DSTM Evaluation Mode - Output: {out_eval.shape}")
        
    except Exception as e:
        print(f"âŒ DSTM Error: {e}")
    
    # æµ‹è¯• MQFF
    print("\nğŸ”¬ Testing MQFF...")
    try:
        mqff = MultiQueryFeatureFusion(
            input_channels=input_channels,
            num_queries=8,
            query_dim=256,
            num_heads=8
        ).to(device)
        
        out_mqff = mqff(x)
        loss = out_mqff.mean()
        loss.backward()
        print(f"âœ… MQFF - Input: {x.shape}, Output: {out_mqff.shape}")
        
    except Exception as e:
        print(f"âŒ MQFF Error: {e}")
    
    # æµ‹è¯• ACGM
    print("\nğŸ”¬ Testing ACGM...")
    try:
        acgm = AdaptiveChannelGroupingMechanism(
            input_channels=input_channels,
            num_groups=8,
            routing_iterations=3
        ).to(device)
        
        out_acgm = acgm(x)
        loss = out_acgm.mean()
        loss.backward()
        print(f"âœ… ACGM - Input: {x.shape}, Output: {out_acgm.shape}")
        
    except Exception as e:
        print(f"âŒ ACGM Error: {e}")
        
        # å°è¯•ç®€åŒ–ç‰ˆæœ¬
        print("ğŸ”„ Trying Simplified ACGM...")
        try:
            acgm_simple = SimplifiedAdaptiveChannelGroupingMechanism(
                input_channels=input_channels,
                num_groups=8
            ).to(device)
            
            out_simple = acgm_simple(x)
            loss = out_simple.mean()
            loss.backward()
            print(f"âœ… Simplified ACGM - Input: {x.shape}, Output: {out_simple.shape}")
            
        except Exception as e:
            print(f"âŒ Simplified ACGM Error: {e}")
    
    # æµ‹è¯•ç»„åˆä½¿ç”¨
    print("\nğŸ”¬ Testing Combined Modules...")
    try:
        dstm = DynamicSpatioTemporalMemory(input_channels, memory_size=64, memory_dim=128).to(device)
        mqff = MultiQueryFeatureFusion(input_channels, num_queries=4, query_dim=128).to(device)
        acgm = SimplifiedAdaptiveChannelGroupingMechanism(input_channels, num_groups=8).to(device)
        
        # é¡ºåºåº”ç”¨
        features = x
        features = dstm(features)
        features = mqff(features)
        features = acgm(features)
        
        loss = features.mean()
        loss.backward()
        
        print(f"âœ… Combined Modules - Final Output: {features.shape}")
        print("âœ… All modules work together successfully!")
        
    except Exception as e:
        print(f"âŒ Combined Modules Error: {e}")
    
    print("\nğŸ‰ Testing completed!")


if __name__ == '__main__':
    test_enhanced_modules()